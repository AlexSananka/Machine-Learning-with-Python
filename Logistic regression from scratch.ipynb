{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #we are going to use this for matrix manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    # steps:\n",
    "    \n",
    "    #initialize weights\n",
    "    #compute gradient\n",
    "    #update weight\n",
    "    #predict\n",
    "    \n",
    "    def fit(self,X,y,thres=0.001,lr=0.001):\n",
    "        self.weights=np.zeros(X.shape[1]+1)\n",
    "        X=self.add_bias(X)\n",
    "        \n",
    "        while True:\n",
    "            gradient=np.dot((y-self.predict(X,False)),X)\n",
    "            update=lr*gradient\n",
    "            self.weights=self.weights+update\n",
    "            if np.max(np.absolute(update))<=thres:break\n",
    "            \n",
    "    def predict(self,X,no_bias=True):\n",
    "        if no_bias:X=self.add_bias(X)\n",
    "        return 1/(1 + np.exp(-1 * np.dot(X, self.weights)))\n",
    "    \n",
    "    def predict_classes(self,X):\n",
    "        return np.vectorize(lambda x: 1 if x>=0.5 else 0)(self.predict(X))\n",
    "    \n",
    "    def add_bias(self,X):\n",
    "        return np.insert(X,0,np.ones(X.shape[0]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could implement the same algorithm using a for loop instead of a while loop as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    \n",
    "    def fit(self,X,y,iter_=1000,lr=.001):\n",
    "        self.weights=np.zeros(X.shape[1]+1)\n",
    "        X=self.add_bias(X)\n",
    "        \n",
    "        for _ in range(iter_):\n",
    "            gradient=np.dot((y-self.predict(X,False)),X)\n",
    "            update=lr*gradient\n",
    "            self.weights=self.weights+update\n",
    "            \n",
    "    def predict(self,X,no_bias=True):\n",
    "        if no_bias: X=self.add_bias(X)\n",
    "        return 1/(1+np.exp(-1*np.dot(X,self.weights)))\n",
    "    \n",
    "    def predict_classes(self,X):\n",
    "        return np.vectorize(lambda x: 1 if x>=0.5 else 0)(self.predict(X))\n",
    "    \n",
    "    def add_bias(self,X):\n",
    "        return np.insert(X,0,np.ones(X.shape[0]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the model using iris dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we take the features\n",
    "Y = (iris.target != 0) * 1 #we take two classes only\n",
    "lr = LogisticRegressor()\n",
    "lr.fit(X,Y, lr=0.001)\n",
    "\n",
    "pre = lr.predict_classes(X)\n",
    "accuracy_score(Y, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
