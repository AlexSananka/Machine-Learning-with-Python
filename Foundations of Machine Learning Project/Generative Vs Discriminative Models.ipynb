{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "<a href='https://aims.edu.gh/'> <img src='http://gh.nexteinstein.org/wp-content/uploads/sites/15/2016/09/logo.jpg' /></a>\n",
    "___\n",
    "# Foundations of Machine Learning \n",
    "\n",
    "## Generative and Discriminative Modelling Project\n",
    "\n",
    "The objective of this project is to compare the perfomance of Naive Bayes, Gaussian Discriminant Analysis and Logistic regression on different data sizes. A detailed descripion of the instructions is shown below.\n",
    "\n",
    "<img src=\"instructions.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import both traing and test\n",
    "drugs_train = pd.read_csv('drugLibTrain_raw.tsv',delimiter='\\t')\n",
    "drugs_test = pd.read_csv('drugLibTest_raw.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first column of data as it is not important\n",
    "drugs_train = drugs_train.drop('Unnamed: 0',axis=1)\n",
    "drugs_test = drugs_test.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "#combine both training and test and shuffle\n",
    "drugs_combined = pd.concat([drugs_train,drugs_test],axis=0)\n",
    "\n",
    "#Shuffle data to avoid any biasness\n",
    "drugs_combined = shuffle(drugs_combined, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=drugs_combined['rating']\n",
    "target=target-1 #shift indices to start from zero\n",
    "target=target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_full=drugs_combined['urlDrugName']+drugs_combined['effectiveness']+drugs_combined['sideEffects']+drugs_combined['condition']+drugs_combined['benefitsReview']+drugs_combined['sideEffectsReview']+drugs_combined['commentsReview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_full=drugs_combined['effectiveness']+drugs_combined['sideEffects'] #using less variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_full = features_full.apply(lambda x: str(x)) #convert all features to strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create instance of countvectorizer \n",
    "vectorizer = CountVectorizer(stop_words='english',binary=True,max_features=350)\n",
    "\n",
    "#fit \n",
    "Transformed_features = vectorizer.fit_transform(features_full)\n",
    "\n",
    "#convert to pandas dataframe\n",
    "Transformed_data = pd.DataFrame(Transformed_features.toarray())\n",
    "\n",
    "# Add  the target variable\n",
    "Transformed_data['Target'] = target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we build three models from scratch. Two Generetative models (Naive Bayes and Gaussian Discriminant Analysis) and one discriminative model (Logistic regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialize probabilities\n",
    "        self.phi_y = 0\n",
    "        self.phi_x = 0\n",
    "        \n",
    "        #computes the values of probability of y given a certain class\n",
    "    def Phi_y_generator(self, y):\n",
    "        self.classes = sorted(np.unique(y))\n",
    "        self.phi_y = np.zeros(len(self.classes))\n",
    "        for i in range(len(self.classes)):\n",
    "            self.phi_y[i] = (np.sum(y==i))/np.sum(len(y))\n",
    "        return self\n",
    "        \n",
    "        #computes the values of probability of x\\y\n",
    "    def Phi_x(self, y,x):\n",
    "        self.n = x.shape[1]\n",
    "        self.phi_x = np.zeros((self.n,len(self.classes)))\n",
    "\n",
    "        for word in range(0,self.n):\n",
    "\n",
    "            for c in self.classes:\n",
    "\n",
    "                self.phi_x[word,c] = ((np.sum((x[:,word]==1)*(y==c)))+1)/(np.sum(y==c)+self.n)\n",
    "\n",
    "\n",
    "        return self\n",
    "        \n",
    "        #fit the data\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.Phi_y_generator(y_train)\n",
    "        self.Phi_x(y_train, x_train)\n",
    "        return self\n",
    "        \n",
    "        #this functon predicts values of target\n",
    "    def predict(self,  x_test):\n",
    "\n",
    "        m,n = x_test.shape\n",
    "        classes = np.arange(self.phi_x.shape[1])\n",
    "        result = np.zeros((m,len(classes)))\n",
    "\n",
    "        for i in range(m):\n",
    "\n",
    "            for c in classes:\n",
    "                x = x_test[i]\n",
    "                phi_x_c = self.phi_x[:,c]\n",
    "                phi_x_y = np.zeros_like(x,dtype=np.float64)\n",
    "                phi_x_y[x==1] = phi_x_c[x==1]\n",
    "                phi_x_y[x==0] = (1- phi_x_c)[x==0]\n",
    "                phi_y_c = self.phi_y[c]\n",
    "                result[i,c] = np.sum(np.log(phi_x_y))+np.log(phi_y_c)\n",
    "\n",
    "        return np.argmax(result,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogistic:\n",
    "    \n",
    "    def __init__(self,lr=0.1,iter_=1000):\n",
    "        self.lr = lr\n",
    "        self.iter_ = iter_\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        #Initialize the parameters\n",
    "        self.weight =[]\n",
    "        X = self.add_bias(X)\n",
    "        m,n = X.shape\n",
    "        \n",
    "        #loop over the classes\n",
    "        classes = np.unique(Y)\n",
    "        for c in classes:\n",
    "            y_new = np.where(Y == c, 1, 0)\n",
    "            w = np.ones(n)\n",
    "            \n",
    "            #loop over the number of iterations\n",
    "            for _ in range(self.iter_):\n",
    "                numerator_sig = np.dot(X, w)\n",
    "                diff = np.dot((y_new- self.sigmoid(numerator_sig)), X)\n",
    "                update = (self.lr * diff)/m\n",
    "                w = w + update\n",
    "            self.weight.append((w,c))\n",
    "        return self\n",
    "            \n",
    "    def sigmoid(self, X):\n",
    "        return 1/(1 + np.exp(-1 * X))\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        return max((x.dot(w), c) for w, c in self.weight)[1]\n",
    "    \n",
    "    def predict_all(self, X):\n",
    "        return [self.predict_one(i) for i in self.add_bias(X)]\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        return sum(self.predict_all(X) == y) / len(y)\n",
    "    \n",
    "    def add_bias(self, X):\n",
    "        return np.insert(X, 0, 1, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDA_Classifier(object):  \n",
    "    \n",
    "    def __init__(self, epsilon = 0.001):\n",
    "        self.epsilon = epsilon #small value to solve non-invertible matrix issue\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.y = y\n",
    "        \n",
    "        self.miu = [np.sum(X[y==k],axis=0)/np.sum(y==k) for k in np.unique(y)]\n",
    "        \n",
    "        m = y.shape[0]\n",
    "        phi = [1/(m)*np.sum(y==k) for k in np.unique(y)]\n",
    "        self.phy = phi\n",
    "        \n",
    "        M = np.zeros_like(X)\n",
    "        \n",
    "        for k in np.unique(y):\n",
    "        \n",
    "            M[y==k] = self.miu[k]\n",
    "            \n",
    "        sigma =((X-M).T@(X-M)) / len(X)\n",
    "        self.sig = sigma\n",
    "        return self\n",
    "    \n",
    "    #compute probability of x|y\n",
    "    def prob_xy(self,X):\n",
    "        n = X.shape[0]\n",
    "        \n",
    "        probs=[]\n",
    "        \n",
    "        f1 = (2*np.pi)**(n/2)*((np.linalg.det(self.sig+self.epsilon*np.eye(n)))**0.5) \n",
    "        for k in np.unique(self.y):\n",
    "            f2 = ((X - self.miu[k])@ (np.linalg.inv(self.sig+self.epsilon*np.eye(n))))@(X - self.miu[k]).T\n",
    "            prob_x_y_k = (1/f1)*np.exp(- 0.5*f2)*self.phy[k]\n",
    "            \n",
    "            probs.append(prob_x_y_k)\n",
    "        return probs\n",
    "    \n",
    "    #function to make the predictions\n",
    "    def predict(self,X):\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            predictions.append(np.argmax(self.prob_xy(X[i])))\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several metrics to check so as to evaluate a model. However, in this project we only use accuracy as the main idea is to compare the performance of the models with different data sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4457831325301205, 0.4578313253012048, 0.4457831325301205],\n",
       " [0.46184738955823296, 0.43373493975903615, 0.46586345381526106],\n",
       " [0.45180722891566266, 0.44176706827309237, 0.43373493975903615],\n",
       " [0.4957780458383595, 0.45958986731001206, 0.48492159227985526]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_sizes = [.1, .3 ,.6, 1] #splits data on 10%, 30%, 60% and 100%\n",
    "accuracies = [[],[],[],[]]     #create list of list to store the accuracies\n",
    "\n",
    "#Loop over the split sizes and compute accuracies for all the models\n",
    "for i in range(len(split_sizes)):\n",
    "    #subset based on the split size\n",
    "    data_subset = Transformed_data.sample(frac=split_sizes[i],random_state=0)\n",
    "    X = data_subset.drop('Target',axis=1)\n",
    "    y = data_subset.Target\n",
    "    \n",
    "    #split data into validaton and training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    #convert dataframe to numpy_arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    #create instances\n",
    "    Naive = NaiveBayesClassifier().fit(X_train, y_train)\n",
    "    GDA = GDA_Classifier().fit(X_train,y_train)\n",
    "    Logistic = MultiClassLogistic().fit(X_train,y_train)\n",
    "\n",
    "    \n",
    "    #predict and store accuracy in a list\n",
    "    predictions_naive = Naive.predict(x_test=X_test)\n",
    "    accuracy_naive = np.mean(predictions_naive==y_test)\n",
    "    accuracies[i].append(accuracy_naive)\n",
    "    \n",
    "    gda_predictions = GDA.predict(X_test)\n",
    "    accuracy_gda = np.mean(gda_predictions==y_test)\n",
    "    accuracies[i].append(accuracy_gda)\n",
    "    \n",
    "    predictions_logistic = Logistic.predict_all(X_test)\n",
    "    accuracy_logistic = Logistic.accuracy(X_test, y_test)\n",
    "    accuracies[i].append(accuracy_logistic)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the perfomance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Names of models\n",
    "labels = ['Naive Bayes', 'GDA', 'Logistic']\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.20  # the width of the bars\n",
    "\n",
    "#set up the figure\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "rects1 = ax.bar(x + 0.00, accuracies[0], width,color = 'b', label='10%')\n",
    "rects2 = ax.bar(x + .20, accuracies[1], width, color = 'g',label='30%')\n",
    "rects3 = ax.bar(x + .40, accuracies[2], width, color = 'r',label='60%')\n",
    "rects4 = ax.bar(x + .60, accuracies[3], width, color = 'k',label='100%')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy by Model and data size')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models\n",
    "  - GDA p(x|y)\n",
    "  - Naive Bayes p(x|y)\n",
    "  \n",
    "Discriminative model\n",
    "  - Logistic p(y|x)\n",
    "\n",
    "\n",
    "GDA works best if the assumption that the features follow a gaussian distribution  hold.\n",
    "\n",
    "GDA makes stronger modelling assumptions and requires less training data to learn if these modelling assumptions are correct.\n",
    "\n",
    "Logistic regression makes weaker assumptions. In case the data is non-Gaussian, logistic works better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the features do not make our models predictive in any way, it rather makes them perform poorly in terms of accuracy.\n",
    "\n",
    "GDA seems to perform better when the data is 10%. Suprisingly, Naive Bayes and Logistic regression have simillar results when we use 10% of the data. \n",
    "\n",
    "It seems like the is no single model that gives outstanding results compared to the others. bIn all the models, the perfomance improves as the data increases.\n",
    "\n",
    "We can say that GDA is less sensitive to data size while logistic shows that its perfomance is affected by data.\n",
    "\n",
    "From the observations, the data does not follow a gaussian distribution and hence GDA does not show better results.\n",
    "\n",
    "Because of the weaker assumptions of logistic regression, it perfoms better compared to GDA  when provided with a good amount of data.\n",
    "\n",
    "\n",
    "In general, we see that the generative models (i.e Naive Bayes and GDA) are less data sensitive. However, the fact that they need less data to learn is not clearly seen. One reason could be the fact that these models make strong assumptions on the data and the assumptions do not hold.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
